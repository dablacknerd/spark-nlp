{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark NLP Sarcasm Dataset Binary Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmafkGaT9V6H",
        "outputId": "a341daf3-cdba-418a-ef8e-a4c4fb8eaf78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxNBWOIp9awa",
        "outputId": "fdbe7338-0472-4140-a0ed-6d036fed886b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed -q spark-nlp==2.4.5 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_272\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_272-8u272-b10-0ubuntu1~18.04-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.272-b10, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHwhVlY39l_Y"
      },
      "source": [
        "data_dir = os.path.join(os.getcwd(),'gdrive','My Drive','Colab Notebooks','Text_Data')\n",
        "file_path = os.path.join(data_dir,'sarcasm_headline_dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-GCrerz-R0f",
        "outputId": "37533454-093c-43da-d2df-8e443fb8a798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start() \n",
        "\n",
        "df = spark.read.csv(file_path,inferSchema=True,header=True)\n",
        "df.printSchema()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- HEADLINE: string (nullable = true)\n",
            " |-- IS_SARCASTIC: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gueuYI-m5zj"
      },
      "source": [
        "df = df.filter((df[\"IS_SARCASTIC\"] == '0') | (df[\"IS_SARCASTIC\"] == '1'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISbJKF-hxs"
      },
      "source": [
        "from pyspark.sql.functions import * \n",
        "from pyspark.sql.types import * \n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.ml.feature import Word2Vec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zqrlxcy-u7T"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import DocumentAssembler,Finisher\n",
        "from sparknlp.annotator import SentenceDetector, Tokenizer, Normalizer, StopWordsCleaner, Lemmatizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuv2xSZp-9tg"
      },
      "source": [
        "# StringIndexer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"IS_SARCASTIC\", outputCol=\"label\")\n",
        "\n",
        "# Get lemmatizer dictionary\n",
        "!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrfsUYC0FLU3"
      },
      "source": [
        "#vector_assembler = VectorAssembler().setInputCols(['embeddings']).setOutputCol('features')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mz_4U7U_iVC"
      },
      "source": [
        "docAssembler = DocumentAssembler().setInputCol(\"HEADLINE\") \\\n",
        "                                  .setOutputCol(\"document\") \\\n",
        "                                  .setCleanupMode(\"shrink_full\")\n",
        "\n",
        "sentence_detector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer().setInputCols(['sentence']).setOutputCol(\"tokens\")\n",
        "\n",
        "normalizer = Normalizer().setInputCols([\"tokens\"]) \\\n",
        "                         .setOutputCol(\"normalized_tokens\") \\\n",
        "                         .setLowercase(True) \\\n",
        "                         .setCleanupPatterns([\"[^\\w\\d\\s]\"])\n",
        "\n",
        "remove_stopwords = StopWordsCleaner().setInputCols([\"normalized_tokens\"]) \\\n",
        "                                    .setOutputCol(\"clean_tokens\") \\\n",
        "                                    .setCaseSensitive(False)\n",
        "\n",
        "lemmatizer = Lemmatizer().setInputCols([\"clean_tokens\"]) \\\n",
        "                         .setOutputCol(\"lemmatized_token\") \\\n",
        "                         .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "finisher = Finisher().setInputCols([\"lemmatized_token\"]) \\\n",
        "                     .setOutputCols(\"lemma_bow\") \\\n",
        "                     .setIncludeMetadata(False)\n",
        "\n",
        "pipeline_stages =[docAssembler, sentence_detector, \n",
        "                  tokenizer, normalizer, remove_stopwords, \n",
        "                  lemmatizer, finisher]\n",
        "            \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW-fNrTOCa9G",
        "outputId": "bc45bbfd-fa46-43db-82a2-dffe9cd70b8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlpPipeline = Pipeline(stages=pipeline_stages)\n",
        "pipelineModel = nlpPipeline.fit(df)\n",
        "\n",
        "df2 = pipelineModel.transform(df)\n",
        "df2.printSchema()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- HEADLINE: string (nullable = true)\n",
            " |-- IS_SARCASTIC: string (nullable = true)\n",
            " |-- lemma_bow: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1h5EdC9C4c1",
        "outputId": "4f1dd607-dc8d-4b8d-ae52-c530b67bb82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.show(5,False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------+\n",
            "|HEADLINE                                                                            |IS_SARCASTIC|lemma_bow                                                                   |\n",
            "+------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------+\n",
            "|former versace store clerk sues over secret 'black code' for minority shoppers      |0           |[former, versace, store, clerk, sue, secret, black, code, minority, shopper]|\n",
            "|the 'roseanne' revival catches up to our thorny political mood, for better and worse|0           |[roseanne, revival, catch, thorny, political, mood, well, bad]              |\n",
            "|mom starting to fear son's web series closest thing she will have to grandchild     |1           |[mom, start, fear, son, web, series, close, thing, grandchild]              |\n",
            "|boehner just wants wife to listen, not come up with alternative debt-reduction ideas|1           |[boehner, want, wife, listen, come, alternative, debtreduction, idea]       |\n",
            "|j.k. rowling wishes snape happy birthday in the most magical way                    |0           |[jk, rowling, wish, snape, happy, birthday, magical, way]                   |\n",
            "+------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GupiayYyC_ZN",
        "outputId": "37dfb047-ef32-4ef7-e67e-fc70688da872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2 = df2.withColumn(\"lemma_bow_size\",size(\"lemma_bow\"))\n",
        "vector_dimension = df2.agg({\"lemma_bow_size\":\"max\"}).collect()[0][0]\n",
        "print(vector_dimension)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSxiDXFCD8cb"
      },
      "source": [
        "word2Vec = Word2Vec(vectorSize= vector_dimension, minCount=0, inputCol=\"lemma_bow\", outputCol=\"features\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhD7EPK0Eig8"
      },
      "source": [
        "classifier = LogisticRegression()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-qUP-AJaLM3"
      },
      "source": [
        "ml_stages =[indexer,word2Vec,classifier]\n",
        "\n",
        "ml_pipeline = Pipeline(stages=ml_stages)\n",
        "\n",
        "train,test = df2.randomSplit([0.7, 0.3],seed = 1984)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69739EUkcDnu"
      },
      "source": [
        "model = ml_pipeline.fit(train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlbJ8qTBcVpo"
      },
      "source": [
        "predictionAndLabels = model.transform(test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPdQJGTUg99p",
        "outputId": "9eedfcca-4408-49d3-fce2-2d744c4e2ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictionAndLabels.printSchema()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- HEADLINE: string (nullable = true)\n",
            " |-- IS_SARCASTIC: string (nullable = true)\n",
            " |-- lemma_bow: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- lemma_bow_size: integer (nullable = false)\n",
            " |-- label: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tnuXVsvdH2w"
      },
      "source": [
        "auc_roc_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',metricName='areaUnderROC')\n",
        "pr_roc_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',metricName='areaUnderPR')\n",
        "precision_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
        "recall_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
        "f1_evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdRVJAlEkJ4a",
        "outputId": "f0585327-8df2-49d5-f979-57fcf13ef716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictionAndLabels.groupBy(\"prediction\").count().show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 5682|\n",
            "|       1.0| 2365|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GsDILIrgGiE",
        "outputId": "6590ad35-102a-4238-9ad4-e3249a944ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"AUC ROC: {0:.2f}\".format(auc_roc_evaluator.evaluate(predictionAndLabels)))\n",
        "print(\"PR ROC: {0:.2f}\".format(pr_roc_evaluator.evaluate(predictionAndLabels)))\n",
        "print(\"Precision: {0:.2f}\".format(precision_evaluator.evaluate(predictionAndLabels)))\n",
        "print(\"Recall ROC: {0:.2f}\".format(recall_evaluator.evaluate(predictionAndLabels)))\n",
        "print(\"F1: {0:.2f}\".format(f1_evaluator.evaluate(predictionAndLabels)))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC ROC: 0.59\n",
            "PR ROC: 0.55\n",
            "Precision: 0.61\n",
            "Recall ROC: 0.62\n",
            "F1: 0.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJRStFRLgvH6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}